{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zackives/upenn-cis-2450/blob/main/cis2450lab2nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPjLRzG_nmMs"
      },
      "source": [
        "# CIS 2450 Lab 2: Pandas\n",
        "\n",
        "###September 8, 2024\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python & Libraries\n",
        "\n",
        "Before starting with Pandas, let's take a look at the relationship between core Python and third-party libraries.\n",
        "\n",
        "There are myriad third-party libraries which users can `install` (download) and `import` to perform certain tasks (eg. Pandas for data analysis, matplotlib for visualizations).\n",
        "\n",
        "If you are running Python for the first time on your local machine, you may need to run `pip install` on the third-party libraries.\n",
        "\n",
        "Google Colab has already `installed` some of the commonly used packages (such as Pandas, Numpy, Matplotlib), so we do not need to run pip install every time we restart runtime. However, you still need to `import` them!\n",
        "\n",
        "<img src = 'https://drive.google.com/uc?id=18IEGTtHQM1HUPHiws3wpA8P08zxRT0It'>\n",
        "\n"
      ],
      "metadata": {
        "id": "RMeEuZL9MI0O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmtoKTB2Hcng"
      },
      "source": [
        "# Pandas 🐼\n",
        "\n",
        "Pandas is an open-source data analysis and manipulation library for Python, widely used in data science, machine learning, and other data-centric tasks. It provides data structures like Series (one-dimensional labeled arrays) and DataFrame (two-dimensional labeled data tables, similar to Excel spreadsheets) that are highly efficient for handling and analyzing structured data.\n",
        "\n",
        "Some key features of Pandas include:\n",
        "\n",
        "- Data Manipulation: Easy-to-use tools for cleaning, filtering, sorting, and grouping data.\n",
        "- Data Wrangling: Support for handling missing data, merging, reshaping, and pivoting datasets.\n",
        "- Data I/O: Capabilities to read from and write to various file formats such as CSV, Excel, SQL databases, JSON, and more.\n",
        "- Data Aggregation: Functions for calculating statistics like mean, sum, median, and standard deviation, with options for grouping and applying custom functions.\n",
        "\n",
        "Pandas simplifies data handling and is highly integrated with other data analysis libraries in Python, making it a cornerstone for data manipulation tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcEJTO4kHnfR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMVJQx-hHwsk"
      },
      "source": [
        "## Series and DataFrames\n",
        "\n",
        "* **Series:** one-dimensional array with hashable axis labels. Parameter is an iterable array-like object, such as lists, dicts, etc.\n",
        "* **DataFrame:** two-dimensional, size-mutable tabular data, consisting of columns of Series. Parameter is an array-like object or DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZsTboy7Hxih"
      },
      "source": [
        "sports = pd.Series(['football', 'basketball',' volleyball','tennis']) #list\n",
        "\n",
        "population = pd.Series({'Germany': 81.3, 'Belgium': 11.3, 'France': 64.3,\n",
        "                        'United Kingdom': 64.9, 'Netherlands': 16.9}) #dict\n",
        "\n",
        "countries = pd.DataFrame({'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
        "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
        "        'area': [30510, 671308, 357050, 41526, 244820],\n",
        "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3YBMxz8H0Hc"
      },
      "source": [
        "sports"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmgEAdNNJwsE"
      },
      "source": [
        "type(sports)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4nHPCDBH2wr"
      },
      "source": [
        "population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnunKRnXJtAJ"
      },
      "source": [
        "type(population)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVogvzK-KAmD"
      },
      "source": [
        "population.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "836UhQ1dKCLb"
      },
      "source": [
        "population.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm7O9SVjKD9k"
      },
      "source": [
        "population / 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38kCCJabKZfu"
      },
      "source": [
        "To access dataframe variables, use the `.` operator or brackets `[ ]`, or access multiple columns with `[[ ]]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlX-HeHsJ0yn"
      },
      "source": [
        "population['Netherlands']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population.Netherlands"
      ],
      "metadata": {
        "id": "7X7dyC-P5wi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOSTN2bBH5Fx"
      },
      "source": [
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countries['population']"
      ],
      "metadata": {
        "id": "u3oblfw-LMDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countries[['population', 'capital']]"
      ],
      "metadata": {
        "id": "jcZRGLgvsLqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mScC0NJaJqQ8"
      },
      "source": [
        "type(countries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmmgSLGnKxsn"
      },
      "source": [
        "type(countries.area) # single column from df is series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKkTGUVLK9sJ"
      },
      "source": [
        "countries['area']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNcEZ5VKLyH7"
      },
      "source": [
        "We can also access dataframes using conditional operators, such as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U7I2rJiXoV-"
      },
      "source": [
        "countries.capital == 'London'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A88u8qxLLy4E"
      },
      "source": [
        "# Extract data for UK/London\n",
        "countries[countries.capital == 'London']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueIpWmGBL2IE"
      },
      "source": [
        "# We can also do this without the .\n",
        "countries[countries['capital'] == 'London']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OWCfx42L4bP"
      },
      "source": [
        "# Getting all countries with area > 100k!\n",
        "\n",
        "countries[countries['area'] > 100000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EXERCISE: Series and DataFrames\n",
        "\n",
        "Which of the following results in a series?\n",
        "\n"
      ],
      "metadata": {
        "id": "DMJen4C8ZCbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A.\n",
        "df[df['city'] == 'Boston']\n",
        "\n",
        "# B.\n",
        "df[df['country'] == 'Germany']['population'] / 100\n",
        "\n",
        "# C.\n",
        "df[['age']].applymap(lambda x: ageGroup(x))"
      ],
      "metadata": {
        "id": "ZukXqmVSZJVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s068sUuI4C7"
      },
      "source": [
        "## Creating New Columns\n",
        "Adding columns to the DataFrame!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kbi6CVkI3be"
      },
      "source": [
        "# basic assignment\n",
        "countries['newVar'] = [1,2,3,None,None]\n",
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRxngu5nH8FX"
      },
      "source": [
        "# using existing columns for assignment\n",
        "# here, we are creating a COMPOSITE VARIABLE defined as:\n",
        "# \"2 * population + sqrt(area)\" for each row in countries\n",
        "countries['newVar2'] = countries.population * 2  + countries.area**0.5\n",
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxlztxbcMCbT"
      },
      "source": [
        "## Apply\n",
        "\n",
        "Apply is a very powerful method which can be used for making major data manipulation tasks. Much faster than standard for loops because of internal optimizations.\n",
        "\n",
        "NOTE: In some assignments, your code could never finish running if you use for loops due to the size of the datasets!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply to a dataframe\n",
        "\n",
        "<img src = 'https://drive.google.com/uc?id=15yFJR7MEMLZdl_GGV-gH6NzgumQ7YfWR'>\n",
        "\n",
        "\n",
        "Apply to a single column\n",
        "\n",
        "<img src = 'https://drive.google.com/uc?id=1BH1mHUNCscEelzn9dFvv386AXrszxwwD'>\n"
      ],
      "metadata": {
        "id": "jRWbBgWgdNGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's practice with a simple dataframe ```df``` which contains a single ```Age``` column."
      ],
      "metadata": {
        "id": "CyhaLoexcSmL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7t1uRLCMO9g"
      },
      "source": [
        "df = pd.DataFrame({'Age': [1, 2, 19, 39, 50]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## APPLY to dataframe\n",
        "# add 10 to all ages less than 50\n",
        "\n",
        "df['NewAge_simple'] = df.apply(lambda x: x['Age'] + 10 if x['Age'] < 50 else x['Age'], axis=1)\n",
        "\n",
        "# the code above can also be written as ...\n",
        "\n",
        "def addTen(num):\n",
        "\treturn num + 10\n",
        "df['NewAge_function'] = df.apply(lambda x: addTen(x['Age']) if x['Age'] < 50 else x['Age'], axis=1)\n",
        "\n",
        "## APPLY to column\n",
        "# the code above can also be written as ...\n",
        "df['NewAge_simple_col'] = df['Age'].apply(lambda x: x + 10 if x < 50 else x)\n",
        "\n",
        "# the code above can also be written as ...\n",
        "df['NewAge_function_col'] = df['Age'].apply(lambda x: addTen(x) if x < 50 else x)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "H3RuIBfraZs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EXERCISE: Apply\n",
        "\n",
        "Which of the following is incorrect?\n"
      ],
      "metadata": {
        "id": "IkUQdLfoZ0za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A.\n",
        "df['Adult'] = df.apply(lambda x: True if x['Age'] >= 18 else False, axis=1)\n",
        "\n",
        "# B.\n",
        "df['Adult'] = df['Age'].apply(lambda x: True if x >= 18 else False)\n",
        "\n",
        "# C.\n",
        "df['Adult'] = df['Age'].apply(lambda x: True if x >= 18 else False, axis=1)"
      ],
      "metadata": {
        "id": "igZkn5ejZ-dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another exercise"
      ],
      "metadata": {
        "id": "8NbpjnmEt0iI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etViTX6Ph-Mj"
      },
      "source": [
        "# Let's call ageBucket on every element in Age, and set that as a new column!\n",
        "\n",
        "def ageBucket(x):\n",
        "    if x<18:\n",
        "        return \"A. <18\"\n",
        "    elif x<25:\n",
        "        return \"B. 18-25\"\n",
        "    elif x<45:\n",
        "        return \"C. 25-45\"\n",
        "    else:\n",
        "        return \"D. >45\"\n",
        "\n",
        "##### EXERCISE #####\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcwSyYeOMb_j"
      },
      "source": [
        "df['AgeBucket2'] = df.apply(lambda x : ageBucket(x['Age']),axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.applymap(lambda x: str(x) + \"--\")"
      ],
      "metadata": {
        "id": "u8EF8XlzA3Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trLNk_6DMeQm"
      },
      "source": [
        "Other derivative methods that you can look into are `map` and `applymap`.\n",
        "* `map` works only on Series but has the same functionality as `apply`.\n",
        "* `applymap` works only on dfs and applies to every element excluding the target column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHZN9Wj63WwJ"
      },
      "source": [
        "## Groupby Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFo0Wrqm3WwJ"
      },
      "source": [
        "##### Some 'theory': the groupby operation (split-apply-combine)\n",
        "\n",
        "The \"group by\" concept: we want to **apply the same function on subsets of your dataframe, based on some key to split the dataframe in subsets**\n",
        "\n",
        "This operation is also referred to as the \"split-apply-combine\" operation, involving the following steps:\n",
        "\n",
        "* **Splitting** the data into groups based on some criteria\n",
        "* **Applying** a function to each group independently\n",
        "* **Combining** the results into a data structure\n",
        "\n",
        "<img src=\"https://github.com/CIS-519/primer-dev/blob/master/pandas-tutorial-master/img/splitApplyCombine.png?raw=1\">\n",
        "\n",
        "Similar to SQL `GROUP BY`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taylor_df = pd.read_csv('https://storage.googleapis.com/penn-cis5450/taylor_swift_spotify.csv')"
      ],
      "metadata": {
        "id": "oher9gF55iPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAj20Vve3WwK"
      },
      "source": [
        "taylor_df.groupby('album')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ELuau23WwL"
      },
      "source": [
        "taylor_df.groupby('album').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pwARtVh3WwO"
      },
      "source": [
        "taylor_df.groupby('album').size().sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGu1111T3WwQ"
      },
      "source": [
        "Grouping on multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHpnkv9d3WwQ"
      },
      "source": [
        "taylor_df.groupby(['album','popularity']).size().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE8wmhMq3WwS"
      },
      "source": [
        "taylor_df.groupby(['album','popularity'])['valence'].mean().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpyIS_Bn3Wwb"
      },
      "source": [
        "## Merge Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPGG_g1H3Wwb"
      },
      "source": [
        "Merging with Pandas works pretty much the same as SQL. There are four merge methods:\n",
        "1. Left\n",
        "2. Right\n",
        "3. Inner\n",
        "4. Outer\n",
        "\n",
        "Basic syntax : pd.merge(left_dataframe, right_dataframe, left_on=\"some_column\", right_on=\"some_column\", how=\"left|right|inner|outer)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzFKDI6I3Wwb"
      },
      "source": [
        "population = pd.DataFrame({'country': ['Germany', 'Belgium', 'France',\n",
        "                        'United Kingdom', 'United States'],'population': [81.3, 11.3, 64.3, 64.9, 65.9]})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntbRi4xh3Wwd"
      },
      "source": [
        "population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec1g-uJw3Wwf"
      },
      "source": [
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaU4-kzk3Wwi"
      },
      "source": [
        "In a Left Merge we are mostly concerned with data on the LEFT side but we would like to add data from\n",
        "the RIGHT side if it has some of the same countries in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffn5Rf3V3Wwj"
      },
      "source": [
        "pd.merge(left=population, right=countries, on=\"country\", how=\"left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRHV_k3Q3Wwl"
      },
      "source": [
        "In a Right Merge we are mostly concerned with data on the RIGHT side but we would like to add data from\n",
        "the LEFT side if it has some of the same countries in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEAd4weA3Wwn"
      },
      "source": [
        "pd.merge(left=population, right=countries, on=\"country\", how=\"right\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGVgL1O73Wwp"
      },
      "source": [
        "With an Inner Merge, we chop up both dataframes and only glue the stuff that matches. If a country isn't in both\n",
        "dataframes, we don't keep it and we don't add NaN's. If no type of join is mentioned, then inner join is the\n",
        "default join."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cumuNz1-3Wwp"
      },
      "source": [
        "pd.merge(left=population, right=countries,on ='country')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwK5dcNV3Wwq"
      },
      "source": [
        "pd.merge(left=population, right=countries,on ='country', how = \"inner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbnDLQwd3Wws"
      },
      "source": [
        "With an Outer Merge, we chop up both dataframes and keep everything from both sides. Then we toss in NaN's to fill\n",
        "any blanks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwv0vZka3Wws"
      },
      "source": [
        "pd.merge(left=population, right=countries,on ='country', how = \"outer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "8lxbwUHH3WxX"
      },
      "source": [
        "#### Missing Data\n",
        "How to handle missing data (NaN's)? Most common commands used are fillna and dropna."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f', 'h'],columns=['one', 'two', 'three'])\n",
        "missing_df"
      ],
      "metadata": {
        "id": "fUIdNBYT8LoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Z4sbjPoR3WxX"
      },
      "source": [
        "missing_df['four'] = 'bar'\n",
        "missing_df['five'] = missing_df['one'] > 0\n",
        "missing_df.loc[['a','c','h'],['one','four']] = np.nan\n",
        "missing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "cOAic3gb3WxZ"
      },
      "source": [
        "# fillna replaces NA/NAN values with the given value in the command.\n",
        "missing_df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "UcJud3dn3Wxf"
      },
      "source": [
        "missing_df['one'].fillna('missing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "L4dr81_h3Wxh"
      },
      "source": [
        "Dropna is used to drop the rows or columns with NA/NAN values.\n",
        "<br>\n",
        "'axis' argument determines if rows or columns which contain missing values are removed.\n",
        "<br>\n",
        "'axis =0': Drop rows which contain missing values.\n",
        "<br>\n",
        "'axis =1': Drop columns which contain missing value.\n",
        "<br>\n",
        "\n",
        "\n",
        "'how' argument determines if row or column is removed from DataFrame, when we have at least one NA or all NA.\n",
        "<br>\n",
        "‘how = any’ : If any NA values are present, drop that row or column. (default)\n",
        "<br>\n",
        "‘how = all’ : If all values are NA, drop that row or column.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "LDrcfuDH3Wxi"
      },
      "source": [
        "missing_df.dropna(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "eRLSnqGz3Wxk"
      },
      "source": [
        "missing_df.dropna(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "t875iBcc3Wxo"
      },
      "source": [
        "missing_df['six'] = np.nan\n",
        "missing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "OG27aNrA3Wxq"
      },
      "source": [
        "missing_df.dropna(axis=1, how = 'all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "v-MB5Pl73Wxr"
      },
      "source": [
        "#dropping rows only where some columns are missing\n",
        "missing_df.dropna(subset = ['one', 'two', 'four'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "u4WwTo6S3Wxx"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}